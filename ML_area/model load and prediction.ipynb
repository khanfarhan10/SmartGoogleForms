{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")                     #Ignoring unnecessory warnings\n",
    "\n",
    "import numpy as np                                  #for large and multi-dimensional arrays\n",
    "import pandas as pd                                 #for data manipulation and analysis\n",
    "import nltk                                         #Natural language processing tool-kit\n",
    "\n",
    "from nltk.corpus import stopwords                   #Stopwords corpus\n",
    "from nltk.stem import PorterStemmer                 # Stemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer          #For Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer          #For TF-IDF\n",
    "from sklearn.ensemble import RandomForestClassifier                  # for rf\n",
    "from gensim.models import Word2Vec                                   #For Word2Vec\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.layers import SpatialDropout1D\n",
    "import re\n",
    "import pickle\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING WITH SOME DATE\n",
    "test = 'last updat st june debarghya das debarghyada com fb co dd deedi fb com dd cornel edu educ cornel univers meng comput scienc dec ithaca ny cornel univers bs comput scienc may ithaca ny colleg engin magna cum laud cum gpa major gpa la martinier boy grad may kolkata india link facebook dd github deedyda linkedin debarghyada youtub deedydash twitter debarghya das quora debarghya das coursework graduat advanc machin learn open sourc softwar engin advanc interact graphic compil practicum cloud comput evolutionari comput defend comput network machin learn undergradu inform retriev oper system artifici intellig practicum function program comput graphic practicum research asst teach asst x unix tool script skill program line java shell python javascript ocaml matlab rail latex line c c css php assembl familiar io android mysql experi facebook softwar engin jan present new york ny coursera kpcb fellow softwar engin intern june sep mountain view ca applic chosen kpcb fellow led ship yoda admin interfac new phoenix platform full stack develop wrote review code js use backbon jade stylus requir scala use play googl softwar engin intern may aug mountain view ca work youtub caption team javascript python plan design develop full stack add edit automat speech recognit caption product creat backbon js like framework caption editor phabric open sourc contributor team leader jan may palo alto ca ithaca ny phabric use daili facebook dropbox quora asana creat meme generat php shell led team mit cornel ic london uhelsinki project research cornel robot learn lab research jan jan ithaca ny work ashesh jain prof ashutosh saxena creat planit tool learn larg scale user prefer feedback plan robot trajectori human environ cornel phonet lab head undergradu research mar may ithaca ny led develop quicktongu first ever breakthrough tongu control game prof sam tilsen aid linguist research award top kpcb engin fellow st microsoft code competit cornel nation jump trade challeng finalist th cs cach race bot tournament nd cs biannual intra class bot tournament nation indian nation mathemat olympiad inmo finalist public jain das saxena planit crowdsourc approach learn plan path larg scale prefer feedback tech report icra press tilsen das b mckee real time articulatori biofeedback electromagnet articulographi linguist vanguard press'\n",
    "snow = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "corpus_test = []\n",
    "# for i in range(0, len(df)):\n",
    "review = re.sub('[^a-zA-Z]', ' ', test)\n",
    "review = review.lower()\n",
    "review = review.split()\n",
    "    \n",
    "review = [snow.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "review = ' '.join(review)\n",
    "corpus_test.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pickle.load(open('./models/tfidf_vectorizer.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tf_test = corpus_test\n",
    "# tf_idf_test = TfidfVectorizer(ngram_range=(1,2),max_features=5000)\n",
    "tf_data_test = v.transform(final_tf_test)\n",
    "tf_data_test.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "loaded_model = pickle.load(open('./models/rf-0.607.pkl', 'rb'))\n",
    "result = loaded_model.predict(tf_data_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rf_result(test,model_path):\n",
    "    snow = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "    corpus_test = []\n",
    "    # for i in range(0, len(df)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', test)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    review = [snow.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus_test.append(review)\n",
    "    \n",
    "    final_tf_test = corpus_test\n",
    "    tf_data_test = v.transform(final_tf_test)\n",
    "    tf_data_test.get_shape()\n",
    "    \n",
    "    # inour case use this file \"./models/rf-0.5215.pkl\" from models folder\n",
    "    \n",
    "    loaded_model = pickle.load(open(model_path, 'rb'))\n",
    "    result = loaded_model.predict(tf_data_test)\n",
    "    return int(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test = 'last updat st june debarghya das debarghyada com fb co dd deedi fb com dd cornel edu educ cornel univers meng comput scienc dec ithaca ny cornel univers bs comput scienc may ithaca ny colleg engin magna cum laud cum gpa major gpa la martinier boy grad may kolkata india link facebook dd github deedyda linkedin debarghyada youtub deedydash twitter debarghya das quora debarghya das coursework graduat advanc machin learn open sourc softwar engin advanc interact graphic compil practicum cloud comput evolutionari comput defend comput network machin learn undergradu inform retriev oper system artifici intellig practicum function program comput graphic practicum research asst teach asst x unix tool script skill program line java shell python javascript ocaml matlab rail latex line c c css php assembl familiar io android mysql experi facebook softwar engin jan present new york ny coursera kpcb fellow softwar engin intern june sep mountain view ca applic chosen kpcb fellow led ship yoda admin interfac new phoenix platform full stack develop wrote review code js use backbon jade stylus requir scala use play googl softwar engin intern may aug mountain view ca work youtub caption team javascript python plan design develop full stack add edit automat speech recognit caption product creat backbon js like framework caption editor phabric open sourc contributor team leader jan may palo alto ca ithaca ny phabric use daili facebook dropbox quora asana creat meme generat php shell led team mit cornel ic london uhelsinki project research cornel robot learn lab research jan jan ithaca ny work ashesh jain prof ashutosh saxena creat planit tool learn larg scale user prefer feedback plan robot trajectori human environ cornel phonet lab head undergradu research mar may ithaca ny led develop quicktongu first ever breakthrough tongu control game prof sam tilsen aid linguist research award top kpcb engin fellow st microsoft code competit cornel nation jump trade challeng finalist th cs cach race bot tournament nd cs biannual intra class bot tournament nation indian nation mathemat olympiad inmo finalist public jain das saxena planit crowdsourc approach learn plan path larg scale prefer feedback tech report icra press tilsen das b mckee real time articulatori biofeedback electromagnet articulographi linguist vanguard press'\n",
    "    model_path = \"./models/rf-0.5215.pkl\"\n",
    "    print(get_rf_result(test,model_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF with RSCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rf_rscv_result(test,model_path):\n",
    "    snow = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "    corpus_test = []\n",
    "    # for i in range(0, len(df)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', test)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    review = [snow.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus_test.append(review)\n",
    "    \n",
    "    final_tf_test = corpus_test\n",
    "    tf_data_test = v.transform(final_tf_test)\n",
    "    tf_data_test.get_shape()\n",
    "    \n",
    "    # inour case use this file \"./models/rf-0.607.pkl\" from models folder\n",
    "    \n",
    "    loaded_model = pickle.load(open(model_path, 'rb'))\n",
    "    result = loaded_model.predict(tf_data_test)\n",
    "    return int(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test = 'last updat st june debarghya das debarghyada com fb co dd deedi fb com dd cornel edu educ cornel univers meng comput scienc dec ithaca ny cornel univers bs comput scienc may ithaca ny colleg engin magna cum laud cum gpa major gpa la martinier boy grad may kolkata india link facebook dd github deedyda linkedin debarghyada youtub deedydash twitter debarghya das quora debarghya das coursework graduat advanc machin learn open sourc softwar engin advanc interact graphic compil practicum cloud comput evolutionari comput defend comput network machin learn undergradu inform retriev oper system artifici intellig practicum function program comput graphic practicum research asst teach asst x unix tool script skill program line java shell python javascript ocaml matlab rail latex line c c css php assembl familiar io android mysql experi facebook softwar engin jan present new york ny coursera kpcb fellow softwar engin intern june sep mountain view ca applic chosen kpcb fellow led ship yoda admin interfac new phoenix platform full stack develop wrote review code js use backbon jade stylus requir scala use play googl softwar engin intern may aug mountain view ca work youtub caption team javascript python plan design develop full stack add edit automat speech recognit caption product creat backbon js like framework caption editor phabric open sourc contributor team leader jan may palo alto ca ithaca ny phabric use daili facebook dropbox quora asana creat meme generat php shell led team mit cornel ic london uhelsinki project research cornel robot learn lab research jan jan ithaca ny work ashesh jain prof ashutosh saxena creat planit tool learn larg scale user prefer feedback plan robot trajectori human environ cornel phonet lab head undergradu research mar may ithaca ny led develop quicktongu first ever breakthrough tongu control game prof sam tilsen aid linguist research award top kpcb engin fellow st microsoft code competit cornel nation jump trade challeng finalist th cs cach race bot tournament nd cs biannual intra class bot tournament nation indian nation mathemat olympiad inmo finalist public jain das saxena planit crowdsourc approach learn plan path larg scale prefer feedback tech report icra press tilsen das b mckee real time articulatori biofeedback electromagnet articulographi linguist vanguard press'\n",
    "    model_path = \"./models/rf-0.607.pkl\"\n",
    "    print(get_rf_rscv_result(test,model_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with .56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating model\n",
    "embedding_vector_features=400\n",
    "voc_size=5000\n",
    "sent_length=400\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./models/final_lstm-0.56.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_path ./models/final_lstm-0.56.h5\n",
    "def get_lstm_result(test,weights_path):\n",
    "    model = load_trained_model(weights_path)\n",
    "    snow = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "    corpus_test = []\n",
    "    # for i in range(0, len(df)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', test)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    review = [snow.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus_test.append(review)\n",
    "\n",
    "    voc_size=5000\n",
    "    onehot_repr=[one_hot(words,voc_size)for words in corpus_test] \n",
    "\n",
    "    sent_length=400\n",
    "    embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "\n",
    "    y_pred_lstm = model.predict_classes(embedded_docs)\n",
    "    \n",
    "    return int(y_pred_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_lstm_result(test,\"./models/final_lstm-0.56.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = model.predict_classes(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm(test):\n",
    "    snow = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "    corpus_test = []\n",
    "    # for i in range(0, len(df)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', test)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    review = [snow.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus_test.append(review)\n",
    "\n",
    "    voc_size=5000\n",
    "    onehot_repr=[one_hot(words,voc_size)for words in corpus_test] \n",
    "\n",
    "    sent_length=400\n",
    "    embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "\n",
    "    y_pred_lstm = model.predict_classes(embedded_docs)\n",
    "    return int(y_pred_lstm)\n",
    "#     return int(y_pred_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_lstm(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from similarity_score_estimation import get_similarity_score\n",
    "ans1 = \"AI is the understanding that machines can interpret, mine, and learn from external data in a way where said machines functionally imitate cognitive practices normally attributed to humans. Artificial intelligence is based on the notion that human thought processes have the ability to both be replicated and mechanized. The history of artificial intelligence dates back to antiquity with philosophers mulling over the idea that artificial beings, mechanical men, and other automatons had existed or could exist in some fashion. To know more about the history you can also visit Analytics Jobs as I got to know about the history of AI and the changes that are happening daily.Thanks to early thinkers, artificial intelligence became increasingly more tangible throughout the 1700s and beyond. Philosophers contemplated how human thinking could be artificially mechanized and manipulated by intelligent non-human machines. The thought processes that fuelled interest in AI originated when classical philosophers, mathematicians, and logicians considered the manipulation of symbols (mechanically), eventually leading to the invention of a programmable digital computer, the Atanasoff Berry Computer (ABC) in the 1940s. This specific invention inspired scientists to move forward with the idea of creating an “electronic brain,” or an artificially intelligent being.In 1955 a leading computer expert, John McCarthy, wrote a proposal to hold a two-month workshop with top computer scientists. The goal was to enable computers to simulate the basics of human intelligence. They sincerely thought that two months would be plenty of time to address all aspects of the problem and start a new era of human intelligence in a machine.Obviously they didn’t succeed, but the event launched the first period of intense AI research. It led to many highly useful developments, but putting the basics of human intelligence into a computer proved to be far more difficult than anyone imagined. After sixty-four years we’re barely able to reproduce the simplest biological intelligence, let alone anything approaching human level. The top researchers currently say that even a primitive artificial general intelligence is a long way off and it’s unknown how it would ever compare to human intelligence.\"\n",
    "ans2 = 'McCarthy invented Artificial Intelligence.The term artificial intelligence was first coined by John McCarthy in 1956 when he held the first academic conference on the subject. But the journey to understand if machines can truly think began much before that. Introduction of AI: Logic was introduced into AI research as early as 1958, by John McCarthy in his Advice Taker proposal. In 1963, J. Alan Robinson had discovered a simple method to implement deduction on computers, the resolution and unification algorithm.He created the term \"artificial intelligence\" and , was a towering figure in computer science at the Stanford University , most of his professional life. In his career, he developed the programming language LISP, played computer chess via telegraph with opponents in Russia and invented computer time-sharing.In proposing the first conference on Artificial Intelligence, McCarthy wrote, \"The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.\" The subsequent conference is considered a watershed moment in computer science. In late 20th century, McCarthy invented the computer programming language LISP, the second oldest programming language after FORTRAN. LISP is still used today and is the programming language of choice for artificial intelligence.'\n",
    "# model_path1 = \"./models/rf-0.607.pkl\"\n",
    "model_path = \"./models/rf-0.5215.pkl\"\n",
    "\n",
    "# say ans2= answer provided by student ans1=answer provided by teacher\n",
    "sim= get_similarity_score(ans1,ans2)\n",
    "# rf_rscv = get_rf_rscv_result(ans2,model_path1)\n",
    "rf = get_rf_result(ans2,model_path)\n",
    "lstm = get_lstm(ans2)\n",
    "\n",
    "total_score = (sim+rf_rscv+rf+lstm)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans2 = 'McCarthy invented Artificial Intelligence.The term artificial intelligence was first coined by John McCarthy in 1956 when he held the first academic conference on the subject. But the journey to understand if machines can truly think began much before that. Introduction of AI: Logic was introduced into AI research as early as 1958, by John McCarthy in his Advice Taker proposal. In 1963, J. Alan Robinson had discovered a simple method to implement deduction on computers, the resolution and unification algorithm.He created the term \"artificial intelligence\" and , was a towering figure in computer science at the Stanford University , most of his professional life. In his career, he developed the programming language LISP, played computer chess via telegraph with opponents in Russia and invented computer time-sharing.In proposing the first conference on Artificial Intelligence, McCarthy wrote, \"The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.\" The subsequent conference is considered a watershed moment in computer science. In late 20th century, McCarthy invented the computer programming language LISP, the second oldest programming language after FORTRAN. LISP is still used today and is the programming language of choice for artificial intelligence.'\n",
    "\n",
    "lstm = get_lstm(ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score = float((sim+rf_rscv+rf+lstm)/4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0e928dcbb782>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mrf_rscv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_rf_rscv_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_path1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_rf_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mlstm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mtotal_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mrf_rscv\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\My_projects\\hackyou\\SMART-GForms_1\\ML_area\\get_lstm_pred.py\u001b[0m in \u001b[0;36mget_lstm\u001b[1;34m(test)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mcorpus_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# for i in range(0, len(df)):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mreview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^a-zA-Z]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mreview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mreview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")                     #Ignoring unnecessory warnings\n",
    "\n",
    "import numpy as np                                  #for large and multi-dimensional arrays\n",
    "import pandas as pd                                 #for data manipulation and analysis\n",
    "import nltk                                         #Natural language processing tool-kit\n",
    "\n",
    "from nltk.corpus import stopwords                   #Stopwords corpus\n",
    "from nltk.stem import PorterStemmer                 # Stemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer          #For Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer          #For TF-IDF\n",
    "from sklearn.ensemble import RandomForestClassifier                  # for rf\n",
    "from gensim.models import Word2Vec                                   #For Word2Vec\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.layers import SpatialDropout1D\n",
    "import re\n",
    "import pickle\n",
    "from similarity_score_estimation import get_similarity_score\n",
    "from get_lstm_pred import get_lstm\n",
    "from get_rf_pred import get_rf_result\n",
    "from get_rf_rscv_pred import get_rf_rscv_result\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    ans1 = \"AI is the understanding that machines can interpret, mine, and learn from external data in a way where said machines functionally imitate cognitive practices normally attributed to humans. Artificial intelligence is based on the notion that human thought processes have the ability to both be replicated and mechanized. The history of artificial intelligence dates back to antiquity with philosophers mulling over the idea that artificial beings, mechanical men, and other automatons had existed or could exist in some fashion. To know more about the history you can also visit Analytics Jobs as I got to know about the history of AI and the changes that are happening daily.Thanks to early thinkers, artificial intelligence became increasingly more tangible throughout the 1700s and beyond. Philosophers contemplated how human thinking could be artificially mechanized and manipulated by intelligent non-human machines. The thought processes that fuelled interest in AI originated when classical philosophers, mathematicians, and logicians considered the manipulation of symbols (mechanically), eventually leading to the invention of a programmable digital computer, the Atanasoff Berry Computer (ABC) in the 1940s. This specific invention inspired scientists to move forward with the idea of creating an “electronic brain,” or an artificially intelligent being.In 1955 a leading computer expert, John McCarthy, wrote a proposal to hold a two-month workshop with top computer scientists. The goal was to enable computers to simulate the basics of human intelligence. They sincerely thought that two months would be plenty of time to address all aspects of the problem and start a new era of human intelligence in a machine.Obviously they didn’t succeed, but the event launched the first period of intense AI research. It led to many highly useful developments, but putting the basics of human intelligence into a computer proved to be far more difficult than anyone imagined. After sixty-four years we’re barely able to reproduce the simplest biological intelligence, let alone anything approaching human level. The top researchers currently say that even a primitive artificial general intelligence is a long way off and it’s unknown how it would ever compare to human intelligence.\"\n",
    "\n",
    "\n",
    "    ans2 = 'McCarthy invented Artificial Intelligence.The term artificial intelligence was first coined by John McCarthy in 1956 when he held the first academic conference on the subject. But the journey to understand if machines can truly think began much before that. Introduction of AI: Logic was introduced into AI research as early as 1958, by John McCarthy in his Advice Taker proposal. In 1963, J. Alan Robinson had discovered a simple method to implement deduction on computers, the resolution and unification algorithm.He created the term \"artificial intelligence\" and , was a towering figure in computer science at the Stanford University , most of his professional life. In his career, he developed the programming language LISP, played computer chess via telegraph with opponents in Russia and invented computer time-sharing.In proposing the first conference on Artificial Intelligence, McCarthy wrote, \"The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.\" The subsequent conference is considered a watershed moment in computer science. In late 20th century, McCarthy invented the computer programming language LISP, the second oldest programming language after FORTRAN. LISP is still used today and is the programming language of choice for artificial intelligence.'\n",
    "\n",
    "\n",
    "    model_path1 = \"./models/rf-0.607.pkl\"\n",
    "    model_path = \"./models/rf-0.5215.pkl\"\n",
    "\n",
    "    # say ans2= answer provided by student, ans1=answer provided by teacher\n",
    "    sim= get_similarity_score(ans1,ans2)\n",
    "    rf_rscv = get_rf_rscv_result(ans2,model_path1)\n",
    "    rf = get_rf_result(ans2,model_path)\n",
    "    lstm = get_lstm(ans2)\n",
    "\n",
    "    total_score = (sim+rf_rscv+rf+lstm)/4\n",
    "    print(total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
